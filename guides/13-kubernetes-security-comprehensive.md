# Kubernetesã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å®Œå…¨å­¦ç¿’ã‚¬ã‚¤ãƒ‰

## ç›®æ¬¡
1. [å­¦ç¿’æ¦‚è¦ã¨å‰æçŸ¥è­˜](#å­¦ç¿’æ¦‚è¦ã¨å‰æçŸ¥è­˜)
2. [AWS ECSã‹ã‚‰Kubernetesã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã¸ã®ç§»è¡Œè¦–ç‚¹](#aws-ecsã‹ã‚‰kubernetesã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã¸ã®ç§»è¡Œè¦–ç‚¹)
3. [Kubernetesã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã®åŸºæœ¬æ¦‚å¿µ](#kubernetesã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã®åŸºæœ¬æ¦‚å¿µ)
4. [RBACï¼ˆRole-Based Access Controlï¼‰](#rbacRole-based-access-control)
5. [Pod Security Standards](#pod-security-standards)
6. [Network Policies ã¨ãƒã‚¤ã‚¯ãƒ­ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³](#network-policies-ã¨ãƒã‚¤ã‚¯ãƒ­ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³)
7. [Secretsç®¡ç†ã¨ãƒ‡ãƒ¼ã‚¿æš—å·åŒ–](#secretsç®¡ç†ã¨ãƒ‡ãƒ¼ã‚¿æš—å·åŒ–)
8. [ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¹ã‚­ãƒ£ãƒ³ã¨è„†å¼±æ€§å¯¾ç­–](#ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¹ã‚­ãƒ£ãƒ³ã¨è„†å¼±æ€§å¯¾ç­–)
9. [ç›£æŸ»ãƒ»ãƒ­ã‚°ãƒ»ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆå¯¾å¿œ](#ç›£æŸ»ãƒ­ã‚°ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆå¯¾å¿œ)
10. [æœ¬ç•ªé‹ç”¨ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£](#æœ¬ç•ªé‹ç”¨ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£)

---

## å­¦ç¿’æ¦‚è¦ã¨å‰æçŸ¥è­˜

### ğŸ¯ å­¦ç¿’ç›®æ¨™

ã“ã®åŒ…æ‹¬çš„ãªã‚¬ã‚¤ãƒ‰ã§ã¯ã€AWS ECSç®¡ç†è€…ãŒKubernetesã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¯¾ç­–ã‚’å®Œå…¨ã«ãƒã‚¹ã‚¿ãƒ¼ã—ã€å®‰å…¨ãªã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼é‹ç”¨ã‚’å®Ÿç¾ã§ãã‚‹ã‚ˆã†ã«ãªã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¾ã™ã€‚

**ç¿’å¾—ã‚¹ã‚­ãƒ«**:
- Kubernetesã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ¢ãƒ‡ãƒ«ã®å®Œå…¨ç†è§£
- RBACè¨­è¨ˆã¨å®Ÿè£…
- Pod Security Standardsã®æ´»ç”¨
- Network Policiesã«ã‚ˆã‚‹ãƒã‚¤ã‚¯ãƒ­ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³
- Secretsç®¡ç†ã¨ãƒ‡ãƒ¼ã‚¿ä¿è­·
- ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ç›£æŸ»ã¨è„…å¨å¯¾å¿œ

### ğŸ“‹ å‰æçŸ¥è­˜ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

- [ ] Kubernetesã®åŸºæœ¬æ¦‚å¿µï¼ˆPodã€Serviceã€Deploymentã€Namespaceï¼‰
- [ ] kubectlåŸºæœ¬æ“ä½œ
- [ ] YAMLè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ç†è§£
- [ ] AWS ECSã§ã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£é‹ç”¨çµŒé¨“
- [ ] ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¨ãƒ•ã‚¡ã‚¤ã‚¢ã‚¦ã‚©ãƒ¼ãƒ«ã®åŸºæœ¬çŸ¥è­˜

### ğŸ• æ¨å®šå­¦ç¿’æ™‚é–“

- **ç†è«–å­¦ç¿’**: 6-8æ™‚é–“
- **å®Ÿè·µæ¼”ç¿’**: 16-20æ™‚é–“
- **ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ç›£æŸ»**: 4-6æ™‚é–“
- **ç·è¨ˆ**: 26-34æ™‚é–“ï¼ˆ4-5æ—¥é–“ï¼‰

---

## AWS ECSã‹ã‚‰Kubernetesã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã¸ã®ç§»è¡Œè¦–ç‚¹

### ECSã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã¨Kubernetesã®å¯¾æ¯”

#### AWS ECS ã§ã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£
```json
{
  "taskDefinition": {
    "executionRoleArn": "arn:aws:iam::account:role/ecsTaskExecutionRole",
    "taskRoleArn": "arn:aws:iam::account:role/ecsTaskRole",
    "networkMode": "awsvpc",
    "requiresCompatibilities": ["EC2", "FARGATE"],
    "placementConstraints": [
      {
        "type": "memberOf",
        "expression": "attribute:ecs.instance-type =~ t3.*"
      }
    ]
  },
  "service": {
    "networkConfiguration": {
      "awsvpcConfiguration": {
        "securityGroups": ["sg-12345678"],
        "subnets": ["subnet-12345678"]
      }
    }
  }
}
```

#### Kubernetes ã§ã®åŒç­‰å®Ÿè£…
```yaml
# ServiceAccountï¼ˆIAMãƒ­ãƒ¼ãƒ«ç›¸å½“ï¼‰
apiVersion: v1
kind: ServiceAccount
metadata:
  name: app-service-account
  namespace: production
  annotations:
    eks.amazonaws.com/role-arn: arn:aws:iam::ACCOUNT:role/K8sAppRole
---
# SecurityContextï¼ˆå®Ÿè¡Œæ¨©é™åˆ¶å¾¡ï¼‰
apiVersion: apps/v1
kind: Deployment
metadata:
  name: secure-app
  namespace: production
spec:
  replicas: 3
  selector:
    matchLabels:
      app: secure-app
  template:
    metadata:
      labels:
        app: secure-app
    spec:
      serviceAccountName: app-service-account
      securityContext:
        runAsNonRoot: true
        runAsUser: 1000
        fsGroup: 2000
        seccompProfile:
          type: RuntimeDefault
      containers:
      - name: app
        image: my-secure-app:latest
        securityContext:
          allowPrivilegeEscalation: false
          readOnlyRootFilesystem: true
          capabilities:
            drop:
            - ALL
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
---
# NetworkPolicyï¼ˆã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚°ãƒ«ãƒ¼ãƒ—ç›¸å½“ï¼‰
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: secure-app-network-policy
  namespace: production
spec:
  podSelector:
    matchLabels:
      app: secure-app
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          name: frontend
    ports:
    - protocol: TCP
      port: 8080
  egress:
  - to:
    - namespaceSelector:
        matchLabels:
          name: database
    ports:
    - protocol: TCP
      port: 5432
```

### é‡è¦ãªæ¦‚å¿µãƒãƒƒãƒ”ãƒ³ã‚°

| AWS ECS | Kubernetes | èª¬æ˜ |
|---------|------------|------|
| IAM Role | ServiceAccount + RBAC | æ¨©é™ç®¡ç† |
| Security Groups | NetworkPolicy | ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ |
| Secrets Manager | Secret + æš—å·åŒ– | æ©Ÿå¯†æƒ…å ±ç®¡ç† |
| CloudTrail | Audit Logs | ç›£æŸ»ãƒ­ã‚° |
| GuardDuty | Falco + ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ„ãƒ¼ãƒ« | è„…å¨æ¤œçŸ¥ |
| VPCè¨­å®š | Network Policies | ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ†é›¢ |

---

## Kubernetesã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã®åŸºæœ¬æ¦‚å¿µ

### ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã®4ã¤ã®æŸ±

#### 1. èªè¨¼ï¼ˆAuthenticationï¼‰
```yaml
# Certificate-basedèªè¨¼è¨­å®šä¾‹
apiVersion: v1
kind: Config
clusters:
- cluster:
    certificate-authority-data: LS0tLS1CRUdJTi...
    server: https://k8s-cluster.example.com
  name: secure-cluster
users:
- name: secure-user
  user:
    client-certificate-data: LS0tLS1CRUdJTi...
    client-key-data: LS0tLS1CRUdJTi...
contexts:
- context:
    cluster: secure-cluster
    user: secure-user
    namespace: production
  name: secure-context
current-context: secure-context
```

#### 2. èªå¯ï¼ˆAuthorizationï¼‰
```yaml
# RBACè¨­å®šä¾‹
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  namespace: production
  name: app-operator
rules:
- apiGroups: [""]
  resources: ["pods", "services"]
  verbs: ["get", "list", "watch"]
- apiGroups: ["apps"]
  resources: ["deployments"]
  verbs: ["get", "list", "watch", "create", "update", "patch"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: app-operator-binding
  namespace: production
subjects:
- kind: User
  name: app-developer
  apiGroup: rbac.authorization.k8s.io
- kind: ServiceAccount
  name: app-service-account
  namespace: production
roleRef:
  kind: Role
  name: app-operator
  apiGroup: rbac.authorization.k8s.io
```

#### 3. ã‚¢ãƒ‰ãƒŸãƒƒã‚·ãƒ§ãƒ³åˆ¶å¾¡ï¼ˆAdmission Controlï¼‰
```yaml
# PodSecurityPolicyï¼ˆéæ¨å¥¨ï¼‰ã®ä»£æ›¿ - Pod Security Standards
apiVersion: v1
kind: Namespace
metadata:
  name: restricted-namespace
  labels:
    pod-security.kubernetes.io/enforce: restricted
    pod-security.kubernetes.io/audit: restricted
    pod-security.kubernetes.io/warn: restricted
---
# OPA Gatekeeperåˆ¶ç´„ä¾‹
apiVersion: templates.gatekeeper.sh/v1beta1
kind: ConstraintTemplate
metadata:
  name: k8srequiredsecuritycontext
spec:
  crd:
    spec:
      names:
        kind: K8sRequiredSecurityContext
      validation:
        type: object
        properties:
          requiredDropCapabilities:
            type: array
            items:
              type: string
  targets:
    - target: admission.k8s.gatekeeper.sh
      rego: |
        package k8srequiredsecuritycontext
        
        violation[{"msg": msg}] {
          container := input.review.object.spec.containers[_]
          not container.securityContext.capabilities.drop
          msg := "ã‚³ãƒ³ãƒ†ãƒŠã«capabilities.dropãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"
        }
```

#### 4. ç›£æŸ»ï¼ˆAuditingï¼‰
```yaml
# ç›£æŸ»ãƒãƒªã‚·ãƒ¼è¨­å®š
apiVersion: audit.k8s.io/v1
kind: Policy
rules:
# é‡è¦ãªãƒªã‚½ãƒ¼ã‚¹ã®å¤‰æ›´ã‚’è¨˜éŒ²
- level: Metadata
  namespaces: ["production", "staging"]
  resources:
  - group: ""
    resources: ["secrets", "configmaps"]
  - group: "apps"
    resources: ["deployments", "statefulsets"]
  omitStages: ["RequestReceived"]

# ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£é–¢é€£ã®æ“ä½œã‚’è©³ç´°è¨˜éŒ²
- level: Request
  users: ["system:serviceaccount:kube-system:*"]
  resources:
  - group: "rbac.authorization.k8s.io"
    resources: ["*"]

# ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã®æ¦‚è¦ã‚’è¨˜éŒ²
- level: Metadata
  omitStages: ["RequestReceived"]
```

---

## RBACï¼ˆRole-Based Access Controlï¼‰

### RBACè¨­è¨ˆã®åŸºæœ¬åŸå‰‡

#### æœ€å°æ¨©é™ã®åŸå‰‡
```yaml
# æ‚ªã„ä¾‹ï¼šéåº¦ãªæ¨©é™ä»˜ä¸
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: bad-developer-role
rules:
- apiGroups: ["*"]
  resources: ["*"]
  verbs: ["*"]  # ã™ã¹ã¦ã®æ“ä½œã‚’è¨±å¯ï¼ˆå±é™ºï¼‰

---
# è‰¯ã„ä¾‹ï¼šå¿…è¦æœ€å°é™ã®æ¨©é™
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  namespace: development
  name: good-developer-role
rules:
# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ç®¡ç†ã®ã¿
- apiGroups: [""]
  resources: ["pods", "services", "configmaps"]
  verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
- apiGroups: ["apps"]
  resources: ["deployments", "replicasets"]
  verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
# ãƒ­ã‚°ã®é–²è¦§ã®ã¿
- apiGroups: [""]
  resources: ["pods/log"]
  verbs: ["get", "list"]
# Secretã®ä½œæˆãƒ»æ›´æ–°ã¯ä¸å¯ã€å‚ç…§ã®ã¿
- apiGroups: [""]
  resources: ["secrets"]
  verbs: ["get", "list"]
```

#### çµ„ç¹”åˆ¥RBACè¨­è¨ˆãƒ‘ã‚¿ãƒ¼ãƒ³

```yaml
# é–‹ç™ºãƒãƒ¼ãƒ ç”¨Role
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  namespace: team-alpha-dev
  name: developer
rules:
- apiGroups: [""]
  resources: ["pods", "services", "configmaps", "persistentvolumeclaims"]
  verbs: ["*"]
- apiGroups: ["apps"]
  resources: ["deployments", "replicasets", "statefulsets"]
  verbs: ["*"]
- apiGroups: [""]
  resources: ["secrets"]
  verbs: ["get", "list"]  # Secretã¯èª­ã¿å–ã‚Šã®ã¿
---
# SREãƒãƒ¼ãƒ ç”¨ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: sre-operator
rules:
# å…¨Namespaceã®Podã¨Serviceã®ç®¡ç†
- apiGroups: [""]
  resources: ["pods", "services", "nodes"]
  verbs: ["get", "list", "watch", "delete"]
# ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°é–¢é€£
- apiGroups: ["metrics.k8s.io"]
  resources: ["*"]
  verbs: ["get", "list"]
# ãƒ­ã‚°ã®ç¢ºèª
- apiGroups: [""]
  resources: ["pods/log", "pods/exec"]
  verbs: ["get", "list", "create"]
---
# ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒãƒ¼ãƒ ç”¨ç›£æŸ»Role
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: security-auditor
rules:
# è¨­å®šã®ç¢ºèªï¼ˆå¤‰æ›´ä¸å¯ï¼‰
- apiGroups: ["*"]
  resources: ["*"]
  verbs: ["get", "list", "watch"]
# RBACè¨­å®šã®ç¢ºèª
- apiGroups: ["rbac.authorization.k8s.io"]
  resources: ["*"]
  verbs: ["get", "list", "watch"]
```

#### ServiceAccount ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

```yaml
# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å°‚ç”¨ServiceAccount
apiVersion: v1
kind: ServiceAccount
metadata:
  name: payment-service-account
  namespace: production
  labels:
    app: payment-service
    team: backend
  annotations:
    # AWS EKSã§ã®IAMé€£æº
    eks.amazonaws.com/role-arn: arn:aws:iam::ACCOUNT:role/PaymentServiceRole
automountServiceAccountToken: false  # ä¸è¦ãªå ´åˆã¯ç„¡åŠ¹åŒ–
---
# å¿…è¦æœ€å°é™ã®æ¨©é™è¨­å®š
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  namespace: production
  name: payment-service-role
rules:
- apiGroups: [""]
  resources: ["configmaps"]
  resourceNames: ["payment-config"]  # ç‰¹å®šã®ConfigMapã®ã¿
  verbs: ["get"]
- apiGroups: [""]
  resources: ["secrets"]
  resourceNames: ["payment-secrets"]  # ç‰¹å®šã®Secretã®ã¿
  verbs: ["get"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: payment-service-binding
  namespace: production
subjects:
- kind: ServiceAccount
  name: payment-service-account
  namespace: production
roleRef:
  kind: Role
  name: payment-service-role
  apiGroup: rbac.authorization.k8s.io
```

---

## Pod Security Standards

### Pod Security Standardsã®3ã¤ã®ãƒ¬ãƒ™ãƒ«

#### 1. Privileged ãƒ¬ãƒ™ãƒ«ï¼ˆåˆ¶é™ãªã—ï¼‰
```yaml
# ç‰¹æ¨©ã‚³ãƒ³ãƒ†ãƒŠãŒå¿…è¦ãªå ´åˆï¼ˆã‚·ã‚¹ãƒ†ãƒ ãƒ¬ãƒ™ãƒ«ãƒ„ãƒ¼ãƒ«ï¼‰
apiVersion: v1
kind: Namespace
metadata:
  name: system-tools
  labels:
    pod-security.kubernetes.io/enforce: privileged
    pod-security.kubernetes.io/audit: privileged
    pod-security.kubernetes.io/warn: privileged
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: node-exporter
  namespace: system-tools
spec:
  selector:
    matchLabels:
      app: node-exporter
  template:
    metadata:
      labels:
        app: node-exporter
    spec:
      hostNetwork: true
      hostPID: true
      containers:
      - name: node-exporter
        image: prom/node-exporter:latest
        securityContext:
          privileged: true  # ç‰¹æ¨©ãƒ¢ãƒ¼ãƒ‰ãŒå¿…è¦
        volumeMounts:
        - name: proc
          mountPath: /host/proc
          readOnly: true
        - name: sys
          mountPath: /host/sys
          readOnly: true
      volumes:
      - name: proc
        hostPath:
          path: /proc
      - name: sys
        hostPath:
          path: /sys
```

#### 2. Baseline ãƒ¬ãƒ™ãƒ«ï¼ˆåŸºæœ¬çš„ãªåˆ¶é™ï¼‰
```yaml
# ä¸€èˆ¬çš„ãªã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ç”¨
apiVersion: v1
kind: Namespace
metadata:
  name: applications
  labels:
    pod-security.kubernetes.io/enforce: baseline
    pod-security.kubernetes.io/audit: baseline
    pod-security.kubernetes.io/warn: baseline
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: web-app
  namespace: applications
spec:
  replicas: 3
  selector:
    matchLabels:
      app: web-app
  template:
    metadata:
      labels:
        app: web-app
    spec:
      securityContext:
        runAsNonRoot: true
        runAsUser: 1000
        supplementalGroups: [2000]
      containers:
      - name: app
        image: nginx:alpine
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
            add:
            - NET_BIND_SERVICE  # ãƒãƒ¼ãƒˆ80,443ãƒã‚¤ãƒ³ãƒ‰ã«å¿…è¦
        ports:
        - containerPort: 8080
        resources:
          requests:
            memory: "128Mi"
            cpu: "100m"
          limits:
            memory: "256Mi"
            cpu: "500m"
```

#### 3. Restricted ãƒ¬ãƒ™ãƒ«ï¼ˆæœ€é«˜ãƒ¬ãƒ™ãƒ«ã®åˆ¶é™ï¼‰
```yaml
# é«˜ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ç’°å¢ƒç”¨
apiVersion: v1
kind: Namespace
metadata:
  name: secure-zone
  labels:
    pod-security.kubernetes.io/enforce: restricted
    pod-security.kubernetes.io/audit: restricted
    pod-security.kubernetes.io/warn: restricted
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: secure-api
  namespace: secure-zone
spec:
  replicas: 3
  selector:
    matchLabels:
      app: secure-api
  template:
    metadata:
      labels:
        app: secure-api
    spec:
      securityContext:
        runAsNonRoot: true
        runAsUser: 1000
        fsGroup: 2000
        seccompProfile:
          type: RuntimeDefault
      containers:
      - name: api
        image: my-secure-api:latest
        securityContext:
          allowPrivilegeEscalation: false
          readOnlyRootFilesystem: true
          capabilities:
            drop:
            - ALL
        volumeMounts:
        - name: tmp-volume
          mountPath: /tmp
        - name: var-run
          mountPath: /var/run
        resources:
          requests:
            memory: "64Mi"
            cpu: "50m"
          limits:
            memory: "128Mi"
            cpu: "200m"
      volumes:
      - name: tmp-volume
        emptyDir: {}
      - name: var-run
        emptyDir: {}
```

### ã‚«ã‚¹ã‚¿ãƒ Admission Controller

```yaml
# OPA Gatekeeper ã«ã‚ˆã‚‹è¿½åŠ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£åˆ¶ç´„
apiVersion: templates.gatekeeper.sh/v1beta1
kind: ConstraintTemplate
metadata:
  name: k8srequiredresources
spec:
  crd:
    spec:
      names:
        kind: K8sRequiredResources
      validation:
        type: object
        properties:
          cpu:
            type: string
          memory:
            type: string
  targets:
    - target: admission.k8s.gatekeeper.sh
      rego: |
        package k8srequiredresources
        
        violation[{"msg": msg}] {
          container := input.review.object.spec.containers[_]
          not container.resources.requests.cpu
          msg := "CPUãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"
        }
        
        violation[{"msg": msg}] {
          container := input.review.object.spec.containers[_]
          not container.resources.requests.memory
          msg := "ãƒ¡ãƒ¢ãƒªãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"
        }
        
        violation[{"msg": msg}] {
          container := input.review.object.spec.containers[_]
          not container.resources.limits.cpu
          msg := "CPUåˆ¶é™ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"
        }
---
# åˆ¶ç´„ã®é©ç”¨
apiVersion: constraints.gatekeeper.sh/v1beta1
kind: K8sRequiredResources
metadata:
  name: must-have-resources
spec:
  match:
    kinds:
      - apiGroups: ["apps"]
        kinds: ["Deployment"]
    excludedNamespaces: ["kube-system", "gatekeeper-system"]
  parameters:
    cpu: "100m"
    memory: "128Mi"
```

---

## Network Policies ã¨ãƒã‚¤ã‚¯ãƒ­ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³

### ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæ‹’å¦ãƒãƒªã‚·ãƒ¼

```yaml
# ã™ã¹ã¦ã®é€šä¿¡ã‚’æ‹’å¦ï¼ˆãƒ›ãƒ¯ã‚¤ãƒˆãƒªã‚¹ãƒˆæ–¹å¼ï¼‰
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: default-deny-all
  namespace: production
spec:
  podSelector: {}
  policyTypes:
  - Ingress
  - Egress
---
# æ˜ç¤ºçš„ã«å¿…è¦ãªé€šä¿¡ã®ã¿è¨±å¯
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: web-to-api-only
  namespace: production
spec:
  podSelector:
    matchLabels:
      app: api-server
  policyTypes:
  - Ingress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app: web-frontend
    ports:
    - protocol: TCP
      port: 8080
```

### 3å±¤ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã® Network Policy

```yaml
# ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰å±¤ï¼šå¤–éƒ¨ã‹ã‚‰ã®ã‚¢ã‚¯ã‚»ã‚¹ã®ã¿è¨±å¯
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: frontend-policy
  namespace: production
spec:
  podSelector:
    matchLabels:
      tier: frontend
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from: []  # å¤–éƒ¨ã‹ã‚‰ã®ã‚¢ã‚¯ã‚»ã‚¹è¨±å¯
    ports:
    - protocol: TCP
      port: 80
    - protocol: TCP
      port: 443
  egress:
  - to:
    - podSelector:
        matchLabels:
          tier: backend
    ports:
    - protocol: TCP
      port: 8080
  # DNSè§£æ±ºã¨HTTPSé€šä¿¡ã‚’è¨±å¯
  - to: []
    ports:
    - protocol: UDP
      port: 53
    - protocol: TCP
      port: 443
---
# ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰å±¤ï¼šãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã‹ã‚‰ã®ã‚¢ã‚¯ã‚»ã‚¹ã®ã¿
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: backend-policy
  namespace: production
spec:
  podSelector:
    matchLabels:
      tier: backend
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          tier: frontend
    ports:
    - protocol: TCP
      port: 8080
  egress:
  - to:
    - podSelector:
        matchLabels:
          tier: database
    ports:
    - protocol: TCP
      port: 5432
  # DNSè§£æ±ºã‚’è¨±å¯
  - to: []
    ports:
    - protocol: UDP
      port: 53
---
# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å±¤ï¼šãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‹ã‚‰ã®ã‚¢ã‚¯ã‚»ã‚¹ã®ã¿
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: database-policy
  namespace: production
spec:
  podSelector:
    matchLabels:
      tier: database
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          tier: backend
    ports:
    - protocol: TCP
      port: 5432
  egress:
  # DNSè§£æ±ºã®ã¿è¨±å¯
  - to: []
    ports:
    - protocol: UDP
      port: 53
```

### åå‰ç©ºé–“é–“ã®åˆ†é›¢

```yaml
# æœ¬ç•ªç’°å¢ƒã®åˆ†é›¢
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: production-isolation
  namespace: production
spec:
  podSelector: {}
  policyTypes:
  - Ingress
  - Egress
  ingress:
  # åŒã˜åå‰ç©ºé–“ã‹ã‚‰ã®ã‚¢ã‚¯ã‚»ã‚¹ã®ã¿è¨±å¯
  - from:
    - namespaceSelector:
        matchLabels:
          name: production
  # Ingress Controllerã‹ã‚‰ã®ã‚¢ã‚¯ã‚»ã‚¹è¨±å¯
  - from:
    - namespaceSelector:
        matchLabels:
          name: ingress-nginx
  egress:
  # åŒã˜åå‰ç©ºé–“å†…ã®é€šä¿¡
  - to:
    - namespaceSelector:
        matchLabels:
          name: production
  # å¤–éƒ¨APIå‘¼ã³å‡ºã—ï¼ˆHTTPSï¼‰
  - to: []
    ports:
    - protocol: TCP
      port: 443
  # DNSè§£æ±º
  - to:
    - namespaceSelector:
        matchLabels:
          name: kube-system
    ports:
    - protocol: UDP
      port: 53
---
# ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ç”¨ã‚¢ã‚¯ã‚»ã‚¹è¨±å¯
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: monitoring-access
  namespace: production
spec:
  podSelector:
    matchLabels:
      monitoring: enabled
  policyTypes:
  - Ingress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          name: monitoring
    ports:
    - protocol: TCP
      port: 9090  # Prometheusãƒ¡ãƒˆãƒªã‚¯ã‚¹
```

---

## Secretsç®¡ç†ã¨ãƒ‡ãƒ¼ã‚¿æš—å·åŒ–

### Kubernetes Secrets ã®é©åˆ‡ãªä½¿ç”¨

#### Secret ã®ä½œæˆã¨ç®¡ç†
```yaml
# åŸºæœ¬çš„ãªSecretä½œæˆ
apiVersion: v1
kind: Secret
metadata:
  name: database-credentials
  namespace: production
  labels:
    app: database
type: Opaque
data:
  # base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰æ¸ˆã¿
  username: cG9zdGdyZXM=
  password: c3VwZXJzZWNyZXRwYXNzd29yZA==
---
# TLSè¨¼æ˜æ›¸Secret
apiVersion: v1
kind: Secret
metadata:
  name: tls-secret
  namespace: production
type: kubernetes.io/tls
data:
  tls.crt: LS0tLS1CRUdJTi...  # è¨¼æ˜æ›¸
  tls.key: LS0tLS1CRUdJTi...  # ç§˜å¯†éµ
---
# Docker Registryèªè¨¼
apiVersion: v1
kind: Secret
metadata:
  name: registry-secret
  namespace: production
type: kubernetes.io/dockerconfigjson
data:
  .dockerconfigjson: eyJhdXRocyI6...
```

#### Secretã®å®‰å…¨ãªä½¿ç”¨æ–¹æ³•
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: secure-app
  namespace: production
spec:
  replicas: 3
  selector:
    matchLabels:
      app: secure-app
  template:
    metadata:
      labels:
        app: secure-app
    spec:
      serviceAccountName: secure-app-sa
      containers:
      - name: app
        image: my-app:latest
        # ç’°å¢ƒå¤‰æ•°ã¨ã—ã¦Secretã‚’ä½¿ç”¨ï¼ˆæ¨å¥¨ã—ãªã„æ–¹æ³•ï¼‰
        env:
        - name: DB_PASSWORD
          valueFrom:
            secretKeyRef:
              name: database-credentials
              key: password
        # Volumeãƒã‚¦ãƒ³ãƒˆï¼ˆæ¨å¥¨æ–¹æ³•ï¼‰
        volumeMounts:
        - name: secret-volume
          mountPath: /etc/secrets
          readOnly: true
        # TLSè¨¼æ˜æ›¸ã®ãƒã‚¦ãƒ³ãƒˆ
        - name: tls-volume
          mountPath: /etc/tls
          readOnly: true
      volumes:
      # Secretã®ãƒœãƒªãƒ¥ãƒ¼ãƒ ãƒã‚¦ãƒ³ãƒˆ
      - name: secret-volume
        secret:
          secretName: database-credentials
          defaultMode: 0400  # èª­ã¿å–ã‚Šå°‚ç”¨
      - name: tls-volume
        secret:
          secretName: tls-secret
          defaultMode: 0400
      # ã‚¤ãƒ¡ãƒ¼ã‚¸å–å¾—ç”¨Secret
      imagePullSecrets:
      - name: registry-secret
```

### æš—å·åŒ–è¨­å®š

#### etcdæš—å·åŒ–ã®è¨­å®š
```yaml
# æš—å·åŒ–è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆencryption-config.yamlï¼‰
apiVersion: apiserver.config.k8s.io/v1
kind: EncryptionConfiguration
resources:
- resources:
  - secrets
  - configmaps
  providers:
  - aescbc:
      keys:
      - name: key1
        secret: c2VjcmV0IGVuY3J5cHRpb24ga2V5
  - identity: {}  # æš—å·åŒ–ãªã—ï¼ˆç§»è¡Œæ™‚ç”¨ï¼‰
```

#### AWS KMSçµ±åˆï¼ˆEKSï¼‰
```yaml
# KMSæš—å·åŒ–ã‚’ä½¿ç”¨ã—ãŸSecret
apiVersion: v1
kind: Secret
metadata:
  name: kms-encrypted-secret
  namespace: production
  annotations:
    # KMSã‚­ãƒ¼ã®æŒ‡å®š
    kms.amazonaws.com/key-id: "arn:aws:kms:region:account:key/key-id"
type: Opaque
data:
  sensitive-data: base64-encoded-data
---
# å¤–éƒ¨Secrets Operatorè¨­å®šä¾‹
apiVersion: external-secrets.io/v1beta1
kind: SecretStore
metadata:
  name: aws-secrets-manager
  namespace: production
spec:
  provider:
    aws:
      service: SecretsManager
      region: ap-northeast-1
      auth:
        secretRef:
          accessKeyID:
            name: aws-credentials
            key: access-key-id
          secretAccessKey:
            name: aws-credentials
            key: secret-access-key
---
apiVersion: external-secrets.io/v1beta1
kind: ExternalSecret
metadata:
  name: database-secret
  namespace: production
spec:
  refreshInterval: 1h
  secretStoreRef:
    name: aws-secrets-manager
    kind: SecretStore
  target:
    name: database-credentials
    creationPolicy: Owner
  data:
  - secretKey: password
    remoteRef:
      key: prod/database/postgres
      property: password
```

### Sealed Secrets ã«ã‚ˆã‚‹ GitOpså¯¾å¿œ

```yaml
# Sealed Secret ä½œæˆä¾‹
apiVersion: bitnami.com/v1alpha1
kind: SealedSecret
metadata:
  name: sealed-database-secret
  namespace: production
spec:
  encryptedData:
    username: AgBy3i4OJSWK+PiTySYZZA9rO43cGDEQAx...
    password: AgBi7i4OJSWK+PiTySYZZA9rO43cGDEQAx...
  template:
    metadata:
      name: database-secret
      namespace: production
    type: Opaque
```

---

## ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¹ã‚­ãƒ£ãƒ³ã¨è„†å¼±æ€§å¯¾ç­–

### ã‚³ãƒ³ãƒ†ãƒŠã‚¤ãƒ¡ãƒ¼ã‚¸ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£

#### ã‚»ã‚­ãƒ¥ã‚¢ãªDockerfileä½œæˆ
```dockerfile
# ã‚»ã‚­ãƒ¥ã‚¢ãªDockerfileä¾‹
FROM node:16-alpine AS builder

# érootãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä½œæˆ
RUN addgroup -g 1001 -S nodejs
RUN adduser -S nextjs -u 1001

# ä¾å­˜é–¢ä¿‚ã®ç®¡ç†
WORKDIR /app
COPY package*.json ./
RUN npm ci --only=production && npm cache clean --force

# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚³ãƒ¼ãƒ‰ã®ã‚³ãƒ”ãƒ¼
COPY --chown=nextjs:nodejs . .
RUN npm run build

# æœ¬ç•ªç”¨ã‚¤ãƒ¡ãƒ¼ã‚¸
FROM node:16-alpine AS runner
WORKDIR /app

# ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆ
RUN apk --no-cache add dumb-init && \
    apk upgrade && \
    rm -rf /var/cache/apk/*

# érootãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä½œæˆ
RUN addgroup -g 1001 -S nodejs
RUN adduser -S nextjs -u 1001

# å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ã‚³ãƒ”ãƒ¼
COPY --from=builder --chown=nextjs:nodejs /app/node_modules ./node_modules
COPY --from=builder --chown=nextjs:nodejs /app/.next ./.next
COPY --from=builder --chown=nextjs:nodejs /app/public ./public
COPY --from=builder --chown=nextjs:nodejs /app/package.json ./package.json

# érootãƒ¦ãƒ¼ã‚¶ãƒ¼ã§å®Ÿè¡Œ
USER nextjs

# ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD curl -f http://localhost:3000/health || exit 1

EXPOSE 3000
CMD ["dumb-init", "node", "server.js"]
```

#### ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚¹ã‚­ãƒ£ãƒ³è¨­å®š
```yaml
# Trivy ã§ã®ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚¹ã‚­ãƒ£ãƒ³ Job
apiVersion: batch/v1
kind: Job
metadata:
  name: image-security-scan
  namespace: security
spec:
  template:
    spec:
      restartPolicy: Never
      containers:
      - name: trivy
        image: aquasec/trivy:latest
        command:
        - trivy
        args:
        - image
        - --exit-code=1  # è„†å¼±æ€§ç™ºè¦‹æ™‚ã¯ç•°å¸¸çµ‚äº†
        - --severity=HIGH,CRITICAL
        - --no-progress
        - my-app:latest
        volumeMounts:
        - name: trivy-cache
          mountPath: /root/.cache
      volumes:
      - name: trivy-cache
        emptyDir: {}
---
# Falco ã«ã‚ˆã‚‹å®Ÿè¡Œæ™‚ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ç›£è¦–
apiVersion: v1
kind: ConfigMap
metadata:
  name: falco-config
  namespace: security
data:
  falco.yaml: |
    rules_file:
      - /etc/falco/falco_rules.yaml
      - /etc/falco/k8s_audit_rules.yaml
      - /etc/falco/rules.d
    
    json_output: true
    json_include_output_property: true
    
    # ã‚«ã‚¹ã‚¿ãƒ ãƒ«ãƒ¼ãƒ«
    - rule: Detect crypto miners
      desc: Detect cryptocurrency miners
      condition: spawned_process and proc.name in (xmrig, cryptonight)
      output: Cryptocurrency miner detected (user=%user.name command=%proc.cmdline container=%container.name)
      priority: CRITICAL
```

### å®Ÿè¡Œæ™‚ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ç›£è¦–

#### Falco ãƒ«ãƒ¼ãƒ«è¨­å®š
```yaml
# ã‚«ã‚¹ã‚¿ãƒ Falcoãƒ«ãƒ¼ãƒ«
apiVersion: v1
kind: ConfigMap
metadata:
  name: custom-falco-rules
  namespace: security
data:
  custom_rules.yaml: |
    - rule: Suspicious File Access
      desc: ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ã¸ã®ç–‘ã‚ã—ã„ã‚¢ã‚¯ã‚»ã‚¹
      condition: >
        open_read and
        fd.filename startswith /etc/ and
        not proc.name in (systemd, kubelet, dockerd)
      output: >
        Suspicious file access
        (user=%user.name command=%proc.cmdline file=%fd.name container=%container.name)
      priority: WARNING
    
    - rule: Privilege Escalation Attempt
      desc: æ¨©é™æ˜‡æ ¼ã®è©¦è¡Œã‚’æ¤œå‡º
      condition: >
        spawned_process and
        proc.name in (sudo, su, doas) and
        container.id != host
      output: >
        Privilege escalation attempt
        (user=%user.name command=%proc.cmdline container=%container.name)
      priority: CRITICAL
    
    - rule: Network Connection to Suspicious Domain
      desc: ç–‘ã‚ã—ã„ãƒ‰ãƒ¡ã‚¤ãƒ³ã¸ã®æ¥ç¶š
      condition: >
        outbound and
        fd.sip.name contains ".onion" or
        fd.sip.name contains "tor2web"
      output: >
        Connection to suspicious domain
        (command=%proc.cmdline domain=%fd.sip.name container=%container.name)
      priority: HIGH
---
# Falco DaemonSet
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: falco
  namespace: security
spec:
  selector:
    matchLabels:
      app: falco
  template:
    metadata:
      labels:
        app: falco
    spec:
      serviceAccount: falco
      hostNetwork: true
      hostPID: true
      containers:
      - name: falco
        image: falcosecurity/falco:latest
        args:
        - /usr/bin/falco
        - --cri=/run/containerd/containerd.sock
        - --k8s-api=https://kubernetes.default.svc.cluster.local
        securityContext:
          privileged: true
        volumeMounts:
        - name: boot-vol
          mountPath: /host/boot
          readOnly: true
        - name: lib-modules
          mountPath: /host/lib/modules
          readOnly: true
        - name: usr-vol
          mountPath: /host/usr
          readOnly: true
        - name: etc-vol
          mountPath: /host/etc
          readOnly: true
        - name: custom-rules
          mountPath: /etc/falco/rules.d
      volumes:
      - name: boot-vol
        hostPath:
          path: /boot
      - name: lib-modules
        hostPath:
          path: /lib/modules
      - name: usr-vol
        hostPath:
          path: /usr
      - name: etc-vol
        hostPath:
          path: /etc
      - name: custom-rules
        configMap:
          name: custom-falco-rules
```

### ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯

#### kube-bench ã«ã‚ˆã‚‹ CIS ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
```yaml
# kube-bench Job
apiVersion: batch/v1
kind: Job
metadata:
  name: kube-bench-master
  namespace: security
spec:
  template:
    spec:
      hostPID: true
      nodeSelector:
        node-role.kubernetes.io/master: ""
      tolerations:
      - key: node-role.kubernetes.io/master
        operator: Exists
        effect: NoSchedule
      restartPolicy: Never
      containers:
      - name: kube-bench
        image: aquasec/kube-bench:latest
        command: ["kube-bench", "master"]
        volumeMounts:
        - name: var-lib-etcd
          mountPath: /var/lib/etcd
          readOnly: true
        - name: etc-kubernetes
          mountPath: /etc/kubernetes
          readOnly: true
      volumes:
      - name: var-lib-etcd
        hostPath:
          path: "/var/lib/etcd"
      - name: etc-kubernetes
        hostPath:
          path: "/etc/kubernetes"
```

---

## ç›£æŸ»ãƒ»ãƒ­ã‚°ãƒ»ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆå¯¾å¿œ

### ç›£æŸ»ãƒ­ã‚°è¨­å®š

#### åŒ…æ‹¬çš„ãªç›£æŸ»ãƒãƒªã‚·ãƒ¼
```yaml
# è©³ç´°ãªç›£æŸ»ãƒãƒªã‚·ãƒ¼è¨­å®š
apiVersion: audit.k8s.io/v1
kind: Policy
rules:
# ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ãªæ“ä½œ
- level: RequestResponse
  users: ["system:admin"]
  resources:
  - group: "rbac.authorization.k8s.io"
    resources: ["*"]
  namespaces: ["kube-system", "production"]

# Secretãƒ»ConfigMapã®æ“ä½œ
- level: Metadata
  resources:
  - group: ""
    resources: ["secrets", "configmaps"]
  omitStages: ["RequestReceived"]

# Podä½œæˆãƒ»å‰Šé™¤
- level: Request
  resources:
  - group: ""
    resources: ["pods"]
  verbs: ["create", "delete", "update", "patch"]

# ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒãƒªã‚·ãƒ¼ã®å¤‰æ›´
- level: RequestResponse
  resources:
  - group: "networking.k8s.io"
    resources: ["networkpolicies"]

# å¤±æ•—ã—ãŸãƒªã‚¯ã‚¨ã‚¹ãƒˆ
- level: Request
  omitStages: ["RequestReceived"]
  resources:
  - group: ""
    resources: ["*"]
  namespaces: ["production"]
  filter: |
    {
      "verb": {"not": "get"},
      "responseStatus": {"code": {"gte": 400}}
    }

# ã‚·ã‚¹ãƒ†ãƒ ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®é‡è¦ãªæ“ä½œ
- level: Metadata
  users: 
  - "system:serviceaccount:kube-system:*"
  verbs: ["create", "update", "patch", "delete"]
  resources:
  - group: ""
    resources: ["nodes", "services", "endpoints"]
```

### ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¤ãƒ™ãƒ³ãƒˆç›£è¦–

#### Prometheus + Alertmanager ã«ã‚ˆã‚‹ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¢ãƒ©ãƒ¼ãƒˆ
```yaml
# ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: falco-metrics
  namespace: security
spec:
  selector:
    matchLabels:
      app: falco
  endpoints:
  - port: metrics
---
# ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¢ãƒ©ãƒ¼ãƒˆãƒ«ãƒ¼ãƒ«
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: security-alerts
  namespace: security
spec:
  groups:
  - name: security.rules
    rules:
    # æ¨©é™æ˜‡æ ¼ã®æ¤œå‡º
    - alert: PrivilegeEscalationDetected
      expr: increase(falco_events_total{rule_name="Privilege Escalation Attempt"}[5m]) > 0
      for: 0m
      labels:
        severity: critical
        category: security
      annotations:
        summary: "æ¨©é™æ˜‡æ ¼ã®è©¦è¡ŒãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ"
        description: "Pod {{ $labels.container_name }} ã§æ¨©é™æ˜‡æ ¼ã®è©¦è¡ŒãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ"
    
    # ç•°å¸¸ãªãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯é€šä¿¡
    - alert: SuspiciousNetworkActivity
      expr: increase(falco_events_total{rule_name="Network Connection to Suspicious Domain"}[5m]) > 0
      for: 0m
      labels:
        severity: high
        category: security
      annotations:
        summary: "ç–‘ã‚ã—ã„ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯é€šä¿¡ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ"
        description: "{{ $labels.container_name }} ã‹ã‚‰ç–‘ã‚ã—ã„ãƒ‰ãƒ¡ã‚¤ãƒ³ã¸ã®æ¥ç¶šãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ"
    
    # å¤±æ•—ã—ãŸèªè¨¼è©¦è¡Œ
    - alert: AuthenticationFailures
      expr: increase(apiserver_audit_total{verb="create",objectRef_resource="tokenreviews",responseStatus_code=~"4.."}[5m]) > 10
      for: 2m
      labels:
        severity: warning
        category: security
      annotations:
        summary: "èªè¨¼å¤±æ•—ãŒå¤šç™ºã—ã¦ã„ã¾ã™"
        description: "éå»5åˆ†é–“ã§{{ $value }}å›ã®èªè¨¼å¤±æ•—ãŒç™ºç”Ÿã—ã¾ã—ãŸ"
    
    # RBACæ¨©é™ã®å¤‰æ›´
    - alert: RBACModification
      expr: increase(apiserver_audit_total{objectRef_apiGroup="rbac.authorization.k8s.io",verb=~"create|update|delete"}[5m]) > 0
      for: 0m
      labels:
        severity: high
        category: security
      annotations:
        summary: "RBACè¨­å®šãŒå¤‰æ›´ã•ã‚Œã¾ã—ãŸ"
        description: "ãƒ¦ãƒ¼ã‚¶ãƒ¼ {{ $labels.user_username }} ãŒRBACè¨­å®šã‚’å¤‰æ›´ã—ã¾ã—ãŸ"
```

### ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆå¯¾å¿œãƒ—ãƒ¬ã‚¤ãƒ–ãƒƒã‚¯

#### è‡ªå‹•å¯¾å¿œã‚¢ã‚¯ã‚·ãƒ§ãƒ³
```yaml
# ç·Šæ€¥æ™‚ã®è‡ªå‹•Podéš”é›¢
apiVersion: batch/v1
kind: Job
metadata:
  name: quarantine-pod
  namespace: security
spec:
  template:
    spec:
      serviceAccountName: incident-responder
      restartPolicy: Never
      containers:
      - name: quarantine
        image: bitnami/kubectl:latest
        command:
        - /bin/bash
        - -c
        - |
          # æ„ŸæŸ“ãŒç–‘ã‚ã‚Œã‚‹Podã‚’éš”é›¢
          POD_NAME="${SUSPICIOUS_POD}"
          NAMESPACE="${POD_NAMESPACE}"
          
          # NetworkPolicyã§é€šä¿¡ã‚’é®æ–­
          cat <<EOF | kubectl apply -f -
          apiVersion: networking.k8s.io/v1
          kind: NetworkPolicy
          metadata:
            name: quarantine-${POD_NAME}
            namespace: ${NAMESPACE}
          spec:
            podSelector:
              matchLabels:
                quarantine: "${POD_NAME}"
            policyTypes:
            - Ingress
            - Egress
          EOF
          
          # Podã«ãƒ©ãƒ™ãƒ«ã‚’è¿½åŠ ã—ã¦éš”é›¢
          kubectl label pod ${POD_NAME} -n ${NAMESPACE} quarantine=${POD_NAME}
          
          # ã‚¢ãƒ©ãƒ¼ãƒˆé€ä¿¡
          curl -X POST "${SLACK_WEBHOOK_URL}" \
            -H 'Content-type: application/json' \
            --data "{\"text\":\"ğŸš¨ Security Alert: Pod ${POD_NAME} has been quarantined\"}"
        env:
        - name: SUSPICIOUS_POD
          value: "compromised-app-12345"
        - name: POD_NAMESPACE
          value: "production"
        - name: SLACK_WEBHOOK_URL
          valueFrom:
            secretKeyRef:
              name: incident-response-secrets
              key: slack-webhook
---
# ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆå¯¾å¿œç”¨ServiceAccount
apiVersion: v1
kind: ServiceAccount
metadata:
  name: incident-responder
  namespace: security
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: incident-responder
rules:
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get", "list", "watch", "update", "patch", "delete"]
- apiGroups: ["networking.k8s.io"]
  resources: ["networkpolicies"]
  verbs: ["create", "update", "patch", "delete"]
- apiGroups: [""]
  resources: ["events"]
  verbs: ["create"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: incident-responder-binding
subjects:
- kind: ServiceAccount
  name: incident-responder
  namespace: security
roleRef:
  kind: ClusterRole
  name: incident-responder
  apiGroup: rbac.authorization.k8s.io
```

---

## æœ¬ç•ªé‹ç”¨ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£

### ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

#### ãƒ‡ãƒ—ãƒ­ã‚¤å‰ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ
```yaml
# ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ¤œè¨¼ç”¨ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
apiVersion: v1
kind: ConfigMap
metadata:
  name: security-checklist
  namespace: security
data:
  checklist.yaml: |
    security_checks:
      rbac:
        - description: "ServiceAccountãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹"
          check: "spec.serviceAccountName != 'default'"
          severity: "high"
        - description: "æœ€å°æ¨©é™ã®åŸå‰‡ãŒé©ç”¨ã•ã‚Œã¦ã„ã‚‹ã‹"
          check: "RBAC rules review"
          severity: "critical"
      
      pod_security:
        - description: "érootãƒ¦ãƒ¼ã‚¶ãƒ¼ã§å®Ÿè¡Œã•ã‚Œã‚‹ã‹"
          check: "spec.securityContext.runAsNonRoot == true"
          severity: "high"
        - description: "ç‰¹æ¨©ãƒ¢ãƒ¼ãƒ‰ãŒç„¡åŠ¹ã‹"
          check: "spec.containers[].securityContext.privileged != true"
          severity: "critical"
        - description: "èª­ã¿å–ã‚Šå°‚ç”¨ãƒ«ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ã‹"
          check: "spec.containers[].securityContext.readOnlyRootFilesystem == true"
          severity: "medium"
        - description: "ä¸è¦ãªCapabilityãŒå‰Šé™¤ã•ã‚Œã¦ã„ã‚‹ã‹"
          check: "spec.containers[].securityContext.capabilities.drop contains 'ALL'"
          severity: "high"
      
      network:
        - description: "NetworkPolicyãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹"
          check: "NetworkPolicy exists in namespace"
          severity: "high"
        - description: "ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæ‹’å¦ãƒãƒªã‚·ãƒ¼ãŒé©ç”¨ã•ã‚Œã¦ã„ã‚‹ã‹"
          check: "Default deny NetworkPolicy exists"
          severity: "critical"
      
      secrets:
        - description: "SecretãŒé©åˆ‡ã«ãƒã‚¦ãƒ³ãƒˆã•ã‚Œã¦ã„ã‚‹ã‹"
          check: "Secret volumes have mode 0400"
          severity: "medium"
        - description: "ä¸è¦ãªSecretè‡ªå‹•ãƒã‚¦ãƒ³ãƒˆãŒç„¡åŠ¹ã‹"
          check: "automountServiceAccountToken == false"
          severity: "low"
      
      resources:
        - description: "ãƒªã‚½ãƒ¼ã‚¹åˆ¶é™ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹"
          check: "resources.limits defined"
          severity: "medium"
        - description: "ãƒªã‚½ãƒ¼ã‚¹è¦æ±‚ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹"
          check: "resources.requests defined"
          severity: "medium"
```

#### ç¶™ç¶šçš„ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ç›£è¦–
```yaml
# ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¹ã‚­ãƒ£ãƒ³CronJob
apiVersion: batch/v1
kind: CronJob
metadata:
  name: security-scan
  namespace: security
spec:
  schedule: "0 2 * * *"  # æ¯æ—¥åˆå‰2æ™‚
  jobTemplate:
    spec:
      template:
        spec:
          restartPolicy: OnFailure
          containers:
          - name: security-scanner
            image: security-scanner:latest
            command:
            - /bin/bash
            - -c
            - |
              #!/bin/bash
              
              echo "=== Daily Security Scan Starting ==="
              
              # 1. kube-benchã§CISãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ
              echo "Running CIS Kubernetes Benchmark..."
              kube-bench run --json > /tmp/benchmark-results.json
              
              # 2. å…¨Podã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¨­å®šç¢ºèª
              echo "Checking Pod security configurations..."
              kubectl get pods --all-namespaces -o json | jq -r '
                .items[] |
                select(.spec.securityContext.runAsRoot == true or .spec.securityContext.runAsNonRoot != true) |
                "\(.metadata.namespace)/\(.metadata.name): Running as root"
              ' > /tmp/root-pods.txt
              
              # 3. éåº¦ãªæ¨©é™ã‚’æŒã¤ServiceAccountç¢ºèª
              echo "Checking for overprivileged ServiceAccounts..."
              kubectl get clusterrolebindings -o json | jq -r '
                .items[] |
                select(.roleRef.name == "cluster-admin") |
                "\(.metadata.name): Has cluster-admin role"
              ' > /tmp/admin-bindings.txt
              
              # 4. NetworkPolicyæœªé©ç”¨ã®Namespaceç¢ºèª
              echo "Checking for namespaces without NetworkPolicies..."
              for ns in $(kubectl get namespaces -o jsonpath='{.items[*].metadata.name}'); do
                if [ $(kubectl get networkpolicy -n $ns --no-headers | wc -l) -eq 0 ]; then
                  echo "$ns: No NetworkPolicy found" >> /tmp/no-netpol.txt
                fi
              done
              
              # 5. çµæœã‚’Slackã«é€ä¿¡
              REPORT=$(cat <<EOF
              ğŸ”’ **Daily Security Scan Report**
              
              **Root Pods Found:**
              $(cat /tmp/root-pods.txt || echo "None")
              
              **Cluster Admin Bindings:**
              $(cat /tmp/admin-bindings.txt || echo "None")
              
              **Namespaces without NetworkPolicy:**
              $(cat /tmp/no-netpol.txt || echo "None")
              EOF
              )
              
              curl -X POST "${SLACK_WEBHOOK_URL}" \
                -H 'Content-type: application/json' \
                --data "{\"text\":\"$REPORT\"}"
              
              echo "=== Security Scan Completed ==="
            env:
            - name: SLACK_WEBHOOK_URL
              valueFrom:
                secretKeyRef:
                  name: security-notifications
                  key: slack-webhook
          serviceAccountName: security-scanner
---
# ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¹ã‚­ãƒ£ãƒŠãƒ¼ç”¨æ¨©é™
apiVersion: v1
kind: ServiceAccount
metadata:
  name: security-scanner
  namespace: security
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: security-scanner
rules:
- apiGroups: ["*"]
  resources: ["*"]
  verbs: ["get", "list", "watch"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: security-scanner-binding
subjects:
- kind: ServiceAccount
  name: security-scanner
  namespace: security
roleRef:
  kind: ClusterRole
  name: security-scanner
  apiGroup: rbac.authorization.k8s.io
```

### ç½å®³å¾©æ—§ã¨ãƒ“ã‚¸ãƒã‚¹ç¶™ç¶šæ€§

#### ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆå¯¾å¿œè¨ˆç”»
```yaml
# ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆå¯¾å¿œç”¨ãƒ„ãƒ¼ãƒ«ã‚»ãƒƒãƒˆ
apiVersion: apps/v1
kind: Deployment
metadata:
  name: incident-response-toolkit
  namespace: security
spec:
  replicas: 1
  selector:
    matchLabels:
      app: incident-response
  template:
    metadata:
      labels:
        app: incident-response
    spec:
      serviceAccountName: incident-responder
      containers:
      - name: toolkit
        image: incident-response:latest
        command: ["/bin/sleep", "infinity"]
        volumeMounts:
        - name: forensics-storage
          mountPath: /forensics
        - name: scripts
          mountPath: /scripts
        env:
        - name: CLUSTER_NAME
          value: "production-cluster"
        - name: INCIDENT_WEBHOOK
          valueFrom:
            secretKeyRef:
              name: incident-response-secrets
              key: webhook-url
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
      volumes:
      - name: forensics-storage
        persistentVolumeClaim:
          claimName: forensics-pvc
      - name: scripts
        configMap:
          name: incident-response-scripts
          defaultMode: 0755
---
# ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆå¯¾å¿œã‚¹ã‚¯ãƒªãƒ—ãƒˆ
apiVersion: v1
kind: ConfigMap
metadata:
  name: incident-response-scripts
  namespace: security
data:
  isolate-pod.sh: |
    #!/bin/bash
    # Podç·Šæ€¥éš”é›¢ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
    POD_NAME=$1
    NAMESPACE=$2
    
    if [ -z "$POD_NAME" ] || [ -z "$NAMESPACE" ]; then
      echo "Usage: $0 <pod-name> <namespace>"
      exit 1
    fi
    
    echo "Isolating pod $POD_NAME in namespace $NAMESPACE"
    
    # NetworkPolicyã§é€šä¿¡é®æ–­
    kubectl apply -f - <<EOF
    apiVersion: networking.k8s.io/v1
    kind: NetworkPolicy
    metadata:
      name: isolate-$POD_NAME
      namespace: $NAMESPACE
    spec:
      podSelector:
        matchLabels:
          name: $POD_NAME
      policyTypes:
      - Ingress
      - Egress
    EOF
    
    # ãƒ©ãƒ™ãƒ«è¿½åŠ 
    kubectl label pod $POD_NAME -n $NAMESPACE status=isolated
    
    # è¨¼è·¡ä¿å­˜
    kubectl describe pod $POD_NAME -n $NAMESPACE > /forensics/pod-$POD_NAME-$(date +%Y%m%d-%H%M%S).txt
    kubectl logs $POD_NAME -n $NAMESPACE --previous > /forensics/logs-$POD_NAME-$(date +%Y%m%d-%H%M%S).txt
    
    echo "Pod $POD_NAME has been isolated and forensics data saved"
  
  collect-evidence.sh: |
    #!/bin/bash
    # è¨¼è·¡åé›†ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
    INCIDENT_ID=$1
    
    if [ -z "$INCIDENT_ID" ]; then
      echo "Usage: $0 <incident-id>"
      exit 1
    fi
    
    EVIDENCE_DIR="/forensics/incident-$INCIDENT_ID"
    mkdir -p $EVIDENCE_DIR
    
    echo "Collecting evidence for incident $INCIDENT_ID"
    
    # ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼çŠ¶æ…‹
    kubectl get all --all-namespaces > $EVIDENCE_DIR/cluster-state.txt
    kubectl get events --all-namespaces --sort-by='.lastTimestamp' > $EVIDENCE_DIR/events.txt
    
    # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¨­å®š
    kubectl get networkpolicies --all-namespaces -o yaml > $EVIDENCE_DIR/networkpolicies.yaml
    kubectl get rolebindings,clusterrolebindings --all-namespaces -o yaml > $EVIDENCE_DIR/rbac.yaml
    
    # ãƒãƒ¼ãƒ‰æƒ…å ±
    kubectl describe nodes > $EVIDENCE_DIR/nodes.txt
    
    # åœ§ç¸®
    tar -czf /forensics/evidence-$INCIDENT_ID-$(date +%Y%m%d-%H%M%S).tar.gz -C /forensics incident-$INCIDENT_ID
    
    echo "Evidence collected and compressed"
```

### ã¾ã¨ã‚

ã“ã®ã‚¬ã‚¤ãƒ‰ã§ã¯ã€AWS ECSç®¡ç†è€…å‘ã‘ã«Kubernetesã§ã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¯¾ç­–ã‚’åŒ…æ‹¬çš„ã«å­¦ç¿’ã™ã‚‹å†…å®¹ã‚’ãŠä¼ãˆã—ã¾ã—ãŸã€‚

**ä¸»è¦ãªå­¦ç¿’ãƒã‚¤ãƒ³ãƒˆ**:

1. **å¤šå±¤é˜²å¾¡ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ**: èªè¨¼ãƒ»èªå¯ãƒ»ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ»å®Ÿè¡Œæ™‚ã®å„ãƒ¬ã‚¤ãƒ¤ãƒ¼ã§ã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£
2. **å®Ÿè·µé‡è¦–**: å®Ÿéš›ã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è„…å¨ã«å¯¾å¿œã§ãã‚‹å…·ä½“çš„ãªè¨­å®šä¾‹
3. **ECSæ¯”è¼ƒ**: æ—¢å­˜ã®AWSã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£çŸ¥è­˜ã‚’æ´»ã‹ã—ãŸç§»è¡Œã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
4. **è‡ªå‹•åŒ–å¯¾å¿œ**: CI/CDãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã«çµ„ã¿è¾¼ã‚ã‚‹ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯
5. **ç¶™ç¶šç›£è¦–**: é‹ç”¨ä¸­ã®è„…å¨æ¤œçŸ¥ã¨ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆå¯¾å¿œ

### ğŸš€ å®Ÿè·µçš„ãªå­¦ç¿’ã‚’å§‹ã‚ã‚ˆã†

ç†è«–ã®å­¦ç¿’ãŒå®Œäº†ã—ãŸã‚‰ã€ãœã²å®Ÿéš›ã«æ‰‹ã‚’å‹•ã‹ã—ã¦å­¦ç¿’ã‚’æ·±ã‚ã¦ãã ã•ã„ã€‚

**ãƒãƒ³ã‚ºã‚ªãƒ³æ¼”ç¿’ã®å ´æ‰€**:
```bash
cd hands-on/k8s-security/
./scripts/setup.sh
```

**æ®µéšçš„ãªæ¼”ç¿’å†…å®¹**:
- **Phase 1**: RBACè¨­è¨ˆã¨å®Ÿè£…ï¼ˆ90-120åˆ†ï¼‰
- **Phase 2**: Pod Security Standardsé©ç”¨ï¼ˆ90-120åˆ†ï¼‰
- **Phase 3**: Network Policieså®Ÿè£…ï¼ˆ120-150åˆ†ï¼‰
- **Phase 4**: Secretsç®¡ç†ã¨æš—å·åŒ–ï¼ˆ90-120åˆ†ï¼‰
- **Phase 5**: ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¹ã‚­ãƒ£ãƒ³ã¨ç›£è¦–ï¼ˆ120-150åˆ†ï¼‰
- **Phase 6**: ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆå¯¾å¿œæ¼”ç¿’ï¼ˆ90-120åˆ†ï¼‰

æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã¨ã—ã¦ã€å®Ÿéš›ã®ç’°å¢ƒã§ã“ã‚Œã‚‰ã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¯¾ç­–ã‚’å®Ÿè£…ã—ã€è‡ªç¤¾ã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¦ä»¶ã«é©ç”¨ã—ã¦ã¿ã¦ãã ã•ã„ã€‚ç¶™ç¶šçš„ãªã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å‘ä¸Šã«ã‚ˆã‚Šã€å®‰å…¨ã§ä¿¡é ¼æ€§ã®é«˜ã„Kubernetesã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼é‹ç”¨ã‚’å®Ÿç¾ã§ãã‚‹ã§ã—ã‚‡ã†ã€‚
